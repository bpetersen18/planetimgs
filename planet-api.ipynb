{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import datetime\n",
    "import time\n",
    "from zipfile import ZipFile\n",
    "import json\n",
    "from pathlib import Path\n",
    "import tomli\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import requests\n",
    "import rasterio as rio\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import aiohttp\n",
    "import asyncio\n",
    "# from geojson import Polygon, Feature, FeatureCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sievers_bound = gpd.read_file('data/sievers_bound.geojson')\n",
    "# cas_bound = gpd.read_file('data/sievers_bound.geojson')\n",
    "# accola_bound = gpd.read_file('data/sievers_bound.geojson')\n",
    "# mud_bound = gpd.read_file('data/mud_creek_watershed_4326.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from distutils.command.config import config\n",
    "class PlanetConfig:\n",
    "    def __init__(self, config_file=\"config.toml\"):\n",
    "        self.config_file = config_file\n",
    "        # self.order_url = 'https://api.planet.com/compute/ops/orders/v2'\n",
    "        self.headers = {'content-type': 'application/json'}\n",
    "        \n",
    "        try:\n",
    "            with open(config_file, \"rb\") as f:\n",
    "                self.config = tomli.load(f)\n",
    "        except EnvironmentError as e:\n",
    "            print(os.strerror(e.errno))\n",
    "            print(\"Missing configiguration file.\")\n",
    "            print(\"Please create a config.toml file with your Planet API key.\")\n",
    "            print(\"Use config.toml.example as a template.\")\n",
    "        match self.config:\n",
    "            case {\n",
    "                \"api\": {\"planet_api_key\": str(), 'item_type': str(), 'image_type': str()},\n",
    "                \"filters\": {\"mask\": str(), 'max_cloud': float(), 'start_date': str(), 'end_date': str()},\n",
    "            }:\n",
    "                pass\n",
    "            case ValueError as e:\n",
    "                print(f'Missing or incorrect value in config.toml')\n",
    "                print(str(e))\n",
    "        self.API_KEY = self.config['api']['planet_api_key']\n",
    "        self.SEARCH_URL = 'https://api.planet.com/data/v1/quick-search'\n",
    "        self.ITEM_TYPE = self.config['api']['item_type']\n",
    "        self.IMAGE_TYPE = self.config['api']['image_type']\n",
    "        self.project_name = self.config['general']['project_name']\n",
    "        self.auth = HTTPBasicAuth(self.API_KEY, '')\n",
    "        self.mask = self.config['filters']['mask']\n",
    "        self.max_cloud = self.config['filters']['max_cloud']\n",
    "        self.start_date = self.config['filters']['start_date']\n",
    "        self.end_date = self.config['filters']['end_date']\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f\"Configuration and filters for Planet API image aquisition\"\n",
    "        )\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PLAK7f862c713f3243fb81cd6b6ce6e26f45'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_config = PlanetConfig()\n",
    "my_config.API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanetImages:\n",
    "    def __init__(self):\n",
    "        self.config = PlanetConfig()\n",
    "        self.date_folder = f'{self.config.start_date}_{self.config.end_date}'\n",
    "        self.thumb_dir = os.path.join('data', 'imagery', f'{self.config.project_name}', f'{self.date_folder}', 'thumbnails')\n",
    "        self.img_dir = os.path.join('data', 'imagery', f'{self.config.project_name}', f'{self.date_folder}')\n",
    "        self.search_json = {}\n",
    "        self.img_count = 0\n",
    "        self.image_ids = []\n",
    "        self.image_list = []\n",
    "        self.unique_dates = []\n",
    "        self.good_imgs = []\n",
    "        self.imgs_to_download = []\n",
    "        self.active_imgs = []\n",
    "        self.all_imgs_active = False\n",
    "        self.downloaded_imgs = []\n",
    "    \n",
    "    def _load_aoi(self):\n",
    "        aoi_geom = gpd.read_file(self.config.mask)\n",
    "        aoi_geom = aoi_geom.to_json()\n",
    "        aoi_geom = json.loads(aoi_geom)\n",
    "        aoi_coords = aoi_geom['features'][0]['geometry']\n",
    "        return aoi_coords\n",
    "    \n",
    "    def search_for_images(self):\n",
    "        aoi = self._load_aoi()\n",
    "        #set start and end dates\n",
    "        start_date = self.config.start_date + 'T00:00:00.000Z'\n",
    "        end_date = self.config.end_date + 'T00:00:00.000Z'\n",
    "        #set the mask or filter for desired AOI\n",
    "        geometry_filter = {\n",
    "        \"type\": \"GeometryFilter\",\n",
    "        \"field_name\": \"geometry\",\n",
    "        \"config\": aoi\n",
    "        }\n",
    "        #set range of dates to search for\n",
    "        date_range_filter = {\n",
    "        \"type\": \"DateRangeFilter\",\n",
    "        \"field_name\": \"acquired\",\n",
    "        \"config\": {\n",
    "            \"gte\": start_date,\n",
    "            \"lte\": end_date\n",
    "        }\n",
    "        }\n",
    "\n",
    "        # filter any images which are more than 10% clouds\n",
    "        cloud_cover_filter = {\n",
    "        \"type\": \"RangeFilter\",\n",
    "        \"field_name\": \"cloud_cover\",\n",
    "        \"config\": {\n",
    "            \"lte\": self.config.max_cloud\n",
    "        }\n",
    "        }\n",
    "\n",
    "        # create a filter that combines our geo and date filters\n",
    "        # could also use an \"OrFilter\"\n",
    "        combined_filter = {\n",
    "        \"type\": \"AndFilter\",\n",
    "        \"config\": [geometry_filter, date_range_filter, cloud_cover_filter]\n",
    "        }\n",
    "        #set what type of Planet scene we want to download\n",
    "        # API request object\n",
    "        search_request = {\n",
    "        \"item_types\": [self.config.ITEM_TYPE], \n",
    "        \"filter\": combined_filter\n",
    "        }\n",
    "        search_result = requests.post(\n",
    "            self.config.SEARCH_URL,\n",
    "            auth=HTTPBasicAuth(self.config.API_KEY, ''), json=search_request)\n",
    "        self.search_json = search_result.json()\n",
    "        return self.search_json\n",
    "    \n",
    "    def get_all_avail_image_ids(self):\n",
    "        #just return which images are available\n",
    "        image_json = self.search_for_images()\n",
    "        self.image_ids = [feature['id'] for feature in image_json['features']]\n",
    "        print(f'There are {len(self.image_ids)} total images available to download.')\n",
    "        return self.image_ids\n",
    "    \n",
    "    def get_unique_image_dates(self) -> list:\n",
    "        image_json = self.search_for_images()\n",
    "        self.image_list = []\n",
    "        self.unique_dates = []\n",
    "        #loop through all images, get unique date, and return image info/feature info\n",
    "        for feature in image_json['features']:\n",
    "            image_id = feature['id']\n",
    "            date = image_id[0:8]\n",
    "            if date not in self.unique_dates:\n",
    "                self.unique_dates.append(date)\n",
    "                self.image_list.append(feature)\n",
    "        num_images = len(self.image_list)\n",
    "        if num_images != 0:\n",
    "            print(f'There are {num_images} unique image dates for download.')\n",
    "            return self.image_list\n",
    "        else:\n",
    "            raise ValueError(\"Image list is empty. Try a new date, location, or filters.\")\n",
    "\n",
    "    def download_image_thumbnails(self) -> None:\n",
    "        image_list = self.image_list\n",
    "        img_total = len(image_list)\n",
    "        counter = 0\n",
    "        if not os.path.exists(self.thumb_dir):\n",
    "            os.makedirs(self.thumb_dir)\n",
    "        for image in image_list:\n",
    "            thumb_url = image['_links']['thumbnail']\n",
    "            img_id = image['id']\n",
    "            thumb_req = requests.get(thumb_url, auth=HTTPBasicAuth(self.config.API_KEY, ''))\n",
    "            downloaded_thumb = glob.glob(f'{self.thumb_dir}/{img_id}.tif')\n",
    "            if not downloaded_thumb:\n",
    "                # print(f\"Downloading thumbnail for {img_id}\")\n",
    "                open(f'{self.thumb_dir}/{img_id}.tif', 'wb').write(thumb_req.content)\n",
    "            else:\n",
    "                pass\n",
    "            # print(feature['_links']['thumbnail'])\n",
    "            # counter += 1\n",
    "        # return(image_list)\n",
    "\n",
    "    def filter_images_for_quality(self) -> list:\n",
    "        thumb_imgs = glob.glob(f'{self.thumb_dir}/*.tif')\n",
    "        self.good_imgs = []\n",
    "        for image in thumb_imgs:\n",
    "            with rio.open(image) as src:\n",
    "                b, g, r, nir = src.read()\n",
    "                b_mean = b.mean()\n",
    "                g_mean = g.mean()\n",
    "                r_mean = r.mean()\n",
    "                nir_mean = nir.mean()\n",
    "                # print(image, b_mean, g_mean, r_mean, nir_mean)\n",
    "                if nir_mean >= 100 and r_mean < 10:\n",
    "                    print(f'{image} is possibly bad and/or corrupted. Double check before downloading.')\n",
    "                else:\n",
    "                    self.good_imgs.append(image)\n",
    "        return self.good_imgs\n",
    "\n",
    "    def get_imgs_to_download(self):\n",
    "        img_base_names = [os.path.basename(img) for img in self.good_imgs]\n",
    "        img_base_names = [i[:len(i)-4] for i in img_base_names]\n",
    "        self.imgs_to_download = [i for i in self.search_json['features'] if i['id'] in img_base_names]\n",
    "        return self.imgs_to_download\n",
    "\n",
    "    def activate_imgs(self):\n",
    "        for i in self.imgs_to_download:\n",
    "            img_id = i['id']\n",
    "            img_links = i['_links']\n",
    "            # dwn_link = img_links['_self']\n",
    "            asset_url = f'https://api.planet.com/data/v1/item-types/{my_config.ITEM_TYPE}/items/{img_id}/assets'\n",
    "            try:\n",
    "                result = \\\n",
    "                requests.get(\n",
    "                    asset_url,\n",
    "                    auth=HTTPBasicAuth(my_config.API_KEY, '')\n",
    "                )\n",
    "                img_status = result.json()[f'{my_config.IMAGE_TYPE}']['status']\n",
    "                if img_status == 'inactive':\n",
    "                    print(f'Image {img_id} is inactive. Attempting to activate.')\n",
    "                    links = result.json()[f'{my_config.IMAGE_TYPE}'][\"_links\"]\n",
    "                    # self_link = links[\"_self\"]\n",
    "                    activation_link = links[\"activate\"]\n",
    "                    # Request activation of the 'analytic' asset:\n",
    "                    activate_result = \\\n",
    "                    requests.get(\n",
    "                        activation_link,\n",
    "                        auth=HTTPBasicAuth(my_config.API_KEY, '')\n",
    "                    )\n",
    "                elif img_status == 'active':\n",
    "                    print(f'Image {img_id} is already active.')\n",
    "                else:\n",
    "                    print(f'Unknown status for image {img_id}')\n",
    "                    self.imgs_to_download.remove(i)\n",
    "            except KeyError:\n",
    "                print(f'Image type {my_config.IMAGE_TYPE} not available for {img_id}')\n",
    "                print(f'Removing image {img_id} from download list.')\n",
    "                print(f'These other images are available for {img_id}: {result.json().keys()}')\n",
    "                self.imgs_to_download.remove(i)\n",
    "        \n",
    "    def check_if_images_active(self):\n",
    "        # check to see if product is active or not\n",
    "        num_loops = 21\n",
    "        count = 0\n",
    "        while(count < num_loops):\n",
    "            for i in self.imgs_to_download:\n",
    "                img_id = i['id']\n",
    "                img_links = i['_links']\n",
    "                asset_url = img_links['assets']\n",
    "                # self_link = img_links['_self']\n",
    "                result = \\\n",
    "                    requests.get(\n",
    "                        asset_url,\n",
    "                        auth=HTTPBasicAuth(my_config.API_KEY, '')\n",
    "                    )\n",
    "                img_status = result.json()[f'{my_config.IMAGE_TYPE}']['status']   \n",
    "                success_states = ['active']\n",
    "                if img_status == 'failed':\n",
    "                    raise Exception()\n",
    "                elif img_status in success_states and i not in self.active_imgs:\n",
    "                    self.active_imgs.append(i)\n",
    "            count += 1\n",
    "            if len(self.active_imgs) == len(self.imgs_to_download):\n",
    "                print('All images ready to download.')\n",
    "                self.all_imgs_active = True\n",
    "                break\n",
    "            time.sleep(30)\n",
    "\n",
    "    def download_images(self):\n",
    "        if self.all_imgs_active == True:\n",
    "            print('Downloading images.')\n",
    "        else:\n",
    "            print('All images may not be active. Downloading those that are.')\n",
    "            print('You may want to run this script again after.')\n",
    "        ###TODO repeating a lot of requests. Clean this up later and implement other requests above.\n",
    "        ###TODO mainly there are 2 '_self' links and both are needed. The first is needed to get download link.\n",
    "        for image in self.active_imgs:\n",
    "            #go through all active images\n",
    "            img_id = image['id']\n",
    "            asset_url = f'https://api.planet.com/data/v1/item-types/{my_config.ITEM_TYPE}/items/{img_id}/assets'\n",
    "            try:\n",
    "                #get the asset info\n",
    "                result = \\\n",
    "                requests.get(\n",
    "                    asset_url,\n",
    "                    auth=HTTPBasicAuth(my_config.API_KEY, '')\n",
    "                )\n",
    "                #get different _self link for these assets\n",
    "                links = result.json()[f'{my_config.IMAGE_TYPE}']['_links']\n",
    "                self_link = links['_self']\n",
    "                self_req = \\\n",
    "                    requests.get(\n",
    "                    self_link,\n",
    "                    auth=HTTPBasicAuth(my_config.API_KEY, '')\n",
    "                )\n",
    "                download_url = self_req.json()[\"location\"]\n",
    "                img_req = requests.get(download_url, auth=HTTPBasicAuth(self.config.API_KEY, ''))\n",
    "                downloaded_img = glob.glob(f'{self.img_dir}/{img_id}.tif')\n",
    "                if not downloaded_img:\n",
    "                    print(f\"Downloading image {img_id}.\")\n",
    "                    open(f'{self.img_dir}/{img_id}.tif', 'wb').write(img_req.content)\n",
    "                else:\n",
    "                    print(f'Image {img_id} already downloaded -- skipping.')\n",
    "                    pass\n",
    "            except:\n",
    "                print('Something went wrong.')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 31 total images available to download.\n",
      "There are 17 unique image dates for download.\n",
      "data\\imagery\\Sievers\\2019-07-01_2019-07-31\\thumbnails\\20190708_164141_67_1059.tif is possibly bad and/or corrupted. Double check before downloading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mattn\\miniconda3\\envs\\gis\\Lib\\site-packages\\rasterio\\__init__.py:321: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 20190730_163301_101b is already active.\n",
      "Image 20190728_162818_1001 is already active.\n",
      "Image 20190725_151708_1054 is already active.\n",
      "Image 20190724_151544_0f2b is already active.\n",
      "Image 20190723_151601_1020 is already active.\n",
      "Image 20190722_162912_101b is already active.\n",
      "Image 20190719_163108_0f3f is already active.\n",
      "Image 20190718_165000_14_1067 is already active.\n",
      "Image 20190714_163108_0f17 is already active.\n",
      "Image 20190709_162920_1013 is already active.\n",
      "Image 20190707_151825_0f4d is already active.\n",
      "Image 20190705_163123_1006 is already active.\n",
      "Image 20190704_163219_0f4e is already active.\n",
      "Image 20190703_152135_0f49 is already active.\n",
      "Image 20190702_151809_1020 is already active.\n",
      "Image type ortho_analytic_4b_sr not available for 20190701_204722_0f1c\n",
      "Removing image 20190701_204722_0f1c from download list.\n",
      "These other images are available for 20190701_204722_0f1c: dict_keys(['basic_udm2', 'ortho_udm2', 'ortho_visual'])\n",
      "All images ready to download.\n",
      "Downloading images.\n",
      "Downloading image 20190730_163301_101b.\n",
      "Downloading image 20190728_162818_1001.\n",
      "Downloading image 20190725_151708_1054.\n",
      "Downloading image 20190724_151544_0f2b.\n",
      "Downloading image 20190723_151601_1020.\n",
      "Downloading image 20190722_162912_101b.\n",
      "Downloading image 20190719_163108_0f3f.\n",
      "Downloading image 20190718_165000_14_1067.\n",
      "Downloading image 20190714_163108_0f17.\n",
      "Downloading image 20190709_162920_1013.\n",
      "Downloading image 20190707_151825_0f4d.\n",
      "Downloading image 20190705_163123_1006.\n",
      "Downloading image 20190704_163219_0f4e.\n"
     ]
    }
   ],
   "source": [
    "plan_imgs = PlanetImages()\n",
    "plan_imgs.get_all_avail_image_ids()\n",
    "plan_imgs.get_unique_image_dates()\n",
    "plan_imgs.download_image_thumbnails()\n",
    "plan_imgs.filter_images_for_quality()\n",
    "plan_imgs.get_imgs_to_download()\n",
    "plan_imgs.activate_imgs()\n",
    "plan_imgs.check_if_images_active()\n",
    "plan_imgs.download_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create an api request from the search specifications\n",
    "# def build_request(aoi_geom, start_date, stop_date):\n",
    "#     '''build a data api search request for clear PSScene 4-Band imagery'''\n",
    "#     item_type = 'PSScene'\n",
    "#     query = filters.and_filter(\n",
    "#         filters.geom_filter(aoi_geom),\n",
    "#         filters.range_filter('clear_percent', gte=90),\n",
    "#         filters.date_range('acquired', gt=start_date),\n",
    "#         filters.date_range('acquired', lt=stop_date)\n",
    "#     )\n",
    "#     return filters.build_search_request(query, ['PSScene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = build_request(aoi_coords, start_date, stop_date)\n",
    "request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search the data api\n",
    "def search_data_api(request, client, limit=500):\n",
    "    result = client.quick_search(request)\n",
    "    \n",
    "    # this returns a generator\n",
    "    return result.items_iter(limit=limit)\n",
    "\n",
    "items = list(search_data_api(request, client))\n",
    "print(len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_items = items[:2]\n",
    "# filter to item ids\n",
    "ids = [i['id'] for i in test_items]\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'tutorial_order'\n",
    "item_type = 'PSScene'\n",
    "# 'analytic_sr_udm2' is the basic surface reflectance corrected image, 4 bands\n",
    "bundle = 'analytic_sr_udm2'\n",
    "# and the 8 band version\n",
    "# bundle = 'analytic_8b_sr_udm2'\n",
    "clip_tool = {'clip': {'aoi': aoi_coords}}\n",
    "# # example of a bandmath tool to calculate NDVI that will overwrite default bands\n",
    "# bandmath_tool = {'bandmath': {\n",
    "#     \"pixel_type\": \"32R\",\n",
    "#     \"b1\": \"(b4 - b3) / (b4+b3)\",\n",
    "#     \"b2\": \"(b4 / b2) - 1\",\n",
    "# }}\n",
    "\n",
    "# tools = [clip_tool, bandmath_tool]\n",
    "tools = clip_tool\n",
    "\n",
    "orders_request = {\n",
    "    'name': name,\n",
    "    'products': [{\n",
    "        'item_ids': ids,\n",
    "        'item_type': item_type,\n",
    "        'product_bundle': bundle\n",
    "    }],\n",
    "    'tools': tools,\n",
    "    'delivery': {\n",
    "        'single_archive': True,\n",
    "        'archive_filename':'{{name}}_{{order_id}}.zip',\n",
    "        'archive_type':'zip'\n",
    "    },\n",
    "        'notifications': {\n",
    "                   'email': False\n",
    "    },\n",
    "}\n",
    "\n",
    "# pprint(orders_request, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_info = client.create_order(orders_request).get()\n",
    "\n",
    "order_id = order_info['id']\n",
    "order_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit below to check if asset is ready and then download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_info['_links']['_self']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poll_for_success(order_id, client, num_loops=50) -> None:\n",
    "    count = 0\n",
    "    while(count < num_loops):\n",
    "        count += 1\n",
    "        order_info = client.get_individual_order(order_id).get()\n",
    "        state = order_info['state']\n",
    "        print(state)\n",
    "        success_states = ['success', 'partial']\n",
    "        if state == 'failed':\n",
    "            raise Exception(response)\n",
    "        elif state in success_states:\n",
    "            break\n",
    "        \n",
    "        time.sleep(30)\n",
    "        \n",
    "poll_for_success(order_id, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data_dir = os.path.join('data', 'demo')\n",
    "# make the download directory if it doesn't exist\n",
    "Path(demo_data_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_url = order_info['_links']['_self']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_order(order_url, auth, overwrite=False):\n",
    "    r = requests.get(order_url, auth=auth)\n",
    "    print(r)\n",
    "\n",
    "    response = r.json()\n",
    "    results = response['_links']['results']\n",
    "    results_urls = [r['location'] for r in results]\n",
    "    results_names = [r['name'] for r in results]\n",
    "    results_paths = [pathlib.Path(os.path.join('data', n)) for n in results_names]\n",
    "    print('{} items to download'.format(len(results_urls)))\n",
    "    \n",
    "    for url, name, path in zip(results_urls, results_names, results_paths):\n",
    "        if overwrite or not path.exists():\n",
    "            print('downloading {} to {}'.format(name, path))\n",
    "            r = requests.get(url, allow_redirects=True)\n",
    "            path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            open(path, 'wb').write(r.content)\n",
    "        else:\n",
    "            print('{} already exists, skipping {}'.format(path, name))\n",
    "            \n",
    "    return dict(zip(results_names, results_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%system planet orders download 4fc4e8f9-58e4-4521-966d-56a34ee41797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('gis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a360326a42d5a28317c13b084cabb92cdb98f783569f1b2d7cf45551f4534edd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
